{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.03, max_features=None, min_df=11,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=frozenset({'anything', 'hence', 'though', 'eg', 'becoming', 'own', 'ourselves', 'move', 'them', 'beyond', 'others', 'against', 'everywhere', 'he', 'herein', 'mostly', 'been', 'himself', 'none', 'show', 'yours', 'already', 'amongst', 'everyone', 'by', 'you', 'once', 'of', 'on', 'she', 'whe...d', 'find', 'otherwise', 'third', 'still', 'latter', 'seems', 'they', 'whereupon', 'that', 'might'}),\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word', binary=True, min_df = 11, max_df = .03)\n",
    "vectorizer.fit(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 9455)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [30:31<00:00, 36.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def LDA(n, X,a, b):\n",
    "    n_kw = np.zeros((n, X.shape[1]))\n",
    "    n_dk = np.zeros((X.shape[0], n))\n",
    "    n_k = np.zeros(n)\n",
    "    \n",
    "    doc, word = X.nonzero()\n",
    "    t = np.random.choice(n, len(doc))\n",
    "    \n",
    "    for i, j, k in zip(word, doc, t):\n",
    "        n_kw[k, i] += 1\n",
    "        n_dk[j, k] += 1\n",
    "        n_k[k] +=1\n",
    "\n",
    "    for i in tqdm(range(50)):\n",
    "        for j in range(len(doc)):\n",
    "            n_kw[t[j], word[j]] -= 1\n",
    "            n_dk[doc[j], t[j]] -=1\n",
    "            n_k[t[j]] -=1\n",
    "            \n",
    "            p = (n_dk[doc[j], :] + a)*(n_kw[:,word[j]] + b[word[j]]) / (n_k + b.sum())\n",
    "            t[j] = np.random.choice(np.arange(n), p=p/p.sum())\n",
    "            \n",
    "            n_kw[t[j], word[j]] += 1\n",
    "            n_dk[doc[j], t[j]] += 1\n",
    "            n_k[t[j]] += 1\n",
    "            \n",
    "    return n_kw, n_dk, n_k, t\n",
    "            \n",
    "n = 20\n",
    "n_kw, n_dk, n_k, t = LDA(n, X_train, np.ones(n), np.ones(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема 1: \tchip\tclinton\tclipper\tencryption\tkeys\tpresident\tprivate\tsecret\tsecure\tsecurity\n",
      "Тема 2: \tdeleted\tgoes\thot\tlooks\tmain\toh\tsounds\tsuggest\twonder\twondering\n",
      "Тема 3: \tcouple\tfigure\tgives\tgoes\thaven\tposted\tposting\treply\tsounds\tunfortunately\n",
      "Тема 4: \tcrime\tgun\tguns\tlaws\tlegal\tlikely\tpolice\trights\tself\tweapons\n",
      "Тема 5: \tca\tcontact\tdate\tdetails\tinternet\tmessage\tnewsgroups\tposted\tposting\trelated\n",
      "Тема 6: \tbike\tcars\tdod\tdriving\tengine\tmiles\tride\troad\tspeed\tturn\n",
      "Тема 7: \tcost\tearth\tlow\tnasa\torbit\tproject\tresearch\tscience\tsystems\tuniversity\n",
      "Тема 8: \tappreciated\tdifference\texactly\thot\tknows\tluck\tpersonally\treading\trecall\tworth\n",
      "Тема 9: \tapple\tboard\tdisk\tmac\tmemory\tmonitor\tpc\tram\tspeed\tvideo\n",
      "Тема 10: \tapplication\tcode\tdisplay\tfiles\tftp\tgraphics\timage\tserver\tsun\twindow\n",
      "Тема 11: \tcountry\thistory\tisrael\tisraeli\tjewish\tjews\tland\tmilitary\tpeace\twar\n",
      "Тема 12: \t13\t17\t18\t19\t21\t22\t23\t24\t26\t27\n",
      "Тема 13: \tcause\tcommon\tdisease\teffect\tfood\tmedical\tresults\ttaking\ttreatment\tusually\n",
      "Тема 14: \t00\tasking\tbox\tcondition\tincludes\tmodel\toffer\tsale\tsell\tshipping\n",
      "Тема 15: \tal\tdave\tdavid\tdeleted\tinternet\tmentioned\toh\tposted\tthinking\tuunet\n",
      "Тема 16: \tbanks\tgeb\tgordon\tintellect\tn3jxp\tpitt\tshameful\tskepticism\tsoon\tsurrender\n",
      "Тема 17: \tcoming\thappen\thappened\tnight\tsaw\tstarted\ttook\twanted\twasn\twent\n",
      "Тема 18: \tbible\tchrist\tchristian\tchristians\tchurch\tclaim\tfaith\tjesus\treligion\tsense\n",
      "Тема 19: \tappreciate\tcouple\texperience\thear\tmiddle\toh\tpay\tsorry\tuniversity\twondering\n",
      "Тема 20: \tbaseball\tgames\thockey\tleague\tplay\tplayer\tplayers\tseason\tteams\twin\n"
     ]
    }
   ],
   "source": [
    "words = np.argsort(n_kw)[:,:-11:-1]\n",
    "\n",
    "for i in range(20):\n",
    "    d = np.zeros((1, X_train.shape[1]))\n",
    "    for j in words[i]:\n",
    "        d[0, j] = 1\n",
    "    print('Тема {}: \\t{}'.format(i + 1, '\\t'.join(vectorizer.inverse_transform(d)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальные темы: 'alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc'.\n",
    "\n",
    "Получили пересечения по темам: спорт, религия, медицина, Middle East, компьютерная графика, транспорт (автомобили), \n",
    "программное обеспечение/компьютерная техника, космос, продажи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
